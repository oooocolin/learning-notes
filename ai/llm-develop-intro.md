---
title: 大模型开发
tags:
  - LLM
  - AI
---
## 一、概述
通常说的 「大模型开发」 并不仅仅是训练参数，还包括多个层面：
- **数据层面**：数据清洗、构建语料库、数据增强。
- **模型层面**：
	- 训练参数：在固定的网络结构下训练参数（权重）。
    - 结构优化：修改网络结构，比如改 `Attention` 机制、加 `MoE`、调整层数/隐藏维度。
- **工程层面**：优化分布式训练、推理效率（如量化、蒸馏、并行策略）。
- **应用层面**：微调（`LoRA/QLoRA`）、提示工程、对齐（`RLHF/DPO`）。
## 二、模型的开源与闭源
- 权重+结构都开源 ：
    比如 `LLaMA`、`Qwen-7B/14B/32B` ，这类模型通常发布 `checkpoint` + `config` + 代码。用户既能看到网络结构，也能加载参数，方便研究和二次开发。
- 只开源权重，不开源代码（很少）：
    有些厂商可能只提供权重文件和一个推理框架（例如 `.bin` 文件 + 提供的 API 代码），这时候你虽然能跑推理，但看不到详细结构，几乎没法修改，只能用他们给定的框架来加载。
- 权重+结构部分开源：
    有的会给一个配置文件（比如 `hidden_size=4096`, `num_heads=32` ...），这样虽然没有完整源码，但你能在常见框架（`Transformers` 等）里复现网络结构，然后把权重 load 进去跑。一般是一些更高参数的大模型。
- 闭源：只能使用 API 调用。
## 三、多模态
多模态的核心就是把不同模态的数据都映射成同一种 “ token 表示” ，然后送进 Transformer 中。一般形式不是重新设计一个大模型，而是在 Transformer 语言模型前挂上不同模态的 特征提取器 + 投影层，再用「QA 元组风格」的数据来教会它理解和使用这些新模态，如图像先特征提取转化为向量。
- 文本大模型训练时，输入通常是：`[用户问题 token] + [回答 token]` ，模型通过预测下一个 token 来学会对话。
- 多模态时，变成：`[图像 token] + [问题 token] + [回答 token]`，或者： `[音频 token] + [问题 token] + [回答 token]`   
本质上，还是在做 “问答对”形式的监督训练，只不过问句里多了别的模态信息。
## 四、专家模型与工作流
### 1. 专家模型
- **思路**：希望把各种功能直接内置到模型内部，不依赖外部流程或插件。
- **特点**：
    - 模型本体“懂得”各种特定领域技能
    - 功能通过训练/微调直接嵌入权重
    - 优点：使用方便，调用简单
    - 缺点：
        - 模型规模可能很大
        - 扩展和迭代困难（添加新技能需要再训练）
        - 不够灵活，适应新任务慢
- **例子**：
	-  AlphaCode（微软 DeepMind）训练出模型直接生成竞赛级代码
    - 医疗/化学领域的大模型：训练时就让模型“懂”医学知识或化学实验设计
### 2. 流程化工作流
- **思路**：模型本身是“通用能力生成器”，各种功能通过外部模块（前处理、后处理、工具调用）组合实现。
- **特点**：
    - 模型本体简单统一：统一 token 生成器
    - 功能由流程、插件或工具链组合实现
    - 优点：灵活、可扩展，容易适配不同任务
    - 缺点：依赖外部系统，工作流复杂
- **例子**：
	- IDE 插件 + LLM → 生成代码
	- Coze / Cursor → 多模块组合实现任务（生成文件、测试、重构）
### 3. 最佳实践
虽然两者在思路上有所区别，但是往往结合使用作为最佳实践。专家模型提升内部智能，工作流负责外部操作和工程化，使大模型生成的能力真正落地到实际应用中。


